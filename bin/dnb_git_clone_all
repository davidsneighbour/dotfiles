#!/bin/bash
# dnb_git_clone_all — Clone all repos for the authenticated GitHub user (via gh)
# - Retrieves ALL repos first (pagination) then clones
# - Skips already cloned repos
# - Submodules initialized recursively; relaxed fallback on failure
# - Continues on errors; records reason; summarizes at end
# - Optional parallel clones with --parallel <N> using Bash jobs
# - Logs to ~/.logs/setup-log-YYYYMMDD-HHMMSS.log
# Requirements: bash 4.3+ (wait -n), gh, jq, git

set -euo pipefail
IFS=$'\n\t'

SCRIPT_NAME="$(basename "$0")"
NOW="$(date +'%Y%m%d-%H%M%S')"
LOG_DIR="${HOME}/.logs"
LOG_FILE="${LOG_DIR}/setup/${NOW}.log"
TMP_DIR="$(mktemp -d -t gh-clone-all.XXXXXXXX)"
REPOS_JSON="${TMP_DIR}/repos.json"
FAIL_FILE="${LOG_FILE}.fail.tmp"

DEST_DIR=''                         # required
VISIBILITY='all'                    # all|public|private
AFFILIATION='owner'                 # owner|all (all -> owner,collaborator,organization_member)
INCLUDE_FORKS='false'
INCLUDE_ARCHIVED='false'
DRY_RUN='false'
VERBOSE='false'
STRICT_EXIT='false'                 # exit 2 if any repo fails
PARALLEL_JOBS=6                     # --parallel N

# ---------- Logging ----------
mkdir -p "${LOG_DIR}"

log() {
  local level="${1}"; shift
  printf '[%s][%s][%s] %s\n' \
    "$(date +'%Y-%m-%d %H:%M:%S')" "${SCRIPT_NAME}" "${level}" "$*" \
    | tee -a "${LOG_FILE}" >&2
}
info()  { log info  "$*"; }
warn()  { log warn  "$*"; }
error() { log error "$*"; }
debug() { if [[ "${VERBOSE}" == 'true' ]]; then log debug "$*"; fi }

print_help() {
  cat <<EOF
${SCRIPT_NAME} — clone all repositories of the authenticated user

Usage:
  ${SCRIPT_NAME} --dest-dir <path> [options]

Required:
  --dest-dir <path>                 Destination directory (or --dest-dir=<path>)

Optional:
  --visibility <all|public|private> Filter by visibility (default: ${VISIBILITY})
  --affiliation <owner|all>         'owner' or 'all' (incl. collaborator & org) (default: owner)
  --include-forks                   Include forked repositories (default: skip)
  --include-archived                Include archived repositories (default: skip)
  --parallel <N>                    Clone up to N repos concurrently (default: ${PARALLEL_JOBS})
  --dry-run                         Show actions without cloning
  --verbose                         Extra logging
  --strict-exit                     Exit with code 2 if any repo fails
  --help                            Show this help

Examples:
  ${SCRIPT_NAME} --dest-dir "\${HOME}/github.com/davidsneighbour" --parallel 6
  ${SCRIPT_NAME} --dest-dir=\${HOME}/src --visibility public --affiliation all --include-forks --verbose
EOF
}

die() {
  error "$*"
  echo
  print_help
  exit 1
}

require_cmd() {
  local cmd="${1}"
  if ! command -v "${cmd}" >/dev/null 2>&1; then
    error "Missing required command: ${cmd}"
    case "${cmd}" in
      jq)  warn "Install: sudo apt-get update && sudo apt-get install --yes jq" ;;
      gh)  warn "Install: sudo apt-get install --yes gh" ;;
      git) warn "Install: sudo apt-get install --yes git" ;;
    esac
    echo
    print_help
    exit 1
  fi
}

cleanup() {
  debug "Cleaning up ${TMP_DIR}"
  rm -rf "${TMP_DIR}"
}
trap cleanup EXIT

# ---------- Arg parsing ----------
parse_args() {
  if [[ $# -eq 0 ]]; then
    print_help
    exit 0
  fi

  while [[ $# -gt 0 ]]; do
    case "${1}" in
      --help|-h) print_help; exit 0 ;;
      --verbose) VERBOSE='true'; shift ;;
      --dry-run) DRY_RUN='true'; shift ;;
      --include-forks) INCLUDE_FORKS='true'; shift ;;
      --include-archived) INCLUDE_ARCHIVED='true'; shift ;;
      --strict-exit) STRICT_EXIT='true'; shift ;;
      --parallel)
        shift; [[ $# -gt 0 ]] || die "--parallel requires a value"
        [[ "${1}" =~ ^[0-9]+$ ]] || die "--parallel must be a positive integer"
        PARALLEL_JOBS="${1}"; shift ;;
      --parallel=*)
        val="${1#*=}"; [[ "${val}" =~ ^[0-9]+$ ]] || die "--parallel must be a positive integer"
        PARALLEL_JOBS="${val}"; shift ;;

      --dest-dir) shift; [[ $# -gt 0 ]] || die "--dest-dir requires a value"; DEST_DIR="${1}"; shift ;;
      --dest-dir=*) DEST_DIR="${1#*=}"; shift ;;

      --visibility) shift; [[ $# -gt 0 ]] || die "--visibility requires a value"
        case "${1}" in all|public|private) VISIBILITY="${1}";; *) die "Invalid --visibility '${1}'";; esac
        shift ;;
      --visibility=*)
        val="${1#*=}"; case "${val}" in all|public|private) VISIBILITY="${val}";; *) die "Invalid --visibility '${val}'";; esac
        shift ;;

      --affiliation) shift; [[ $# -gt 0 ]] || die "--affiliation requires a value"
        case "${1}" in
          owner) AFFILIATION='owner' ;;
          all)   AFFILIATION='owner,collaborator,organization_member' ;;
          *)     die "Invalid --affiliation '${1}' (owner|all)" ;;
        esac
        shift ;;
      --affiliation=*)
        val="${1#*=}"
        case "${val}" in
          owner) AFFILIATION='owner' ;;
          all)   AFFILIINATION='owner,collaborator,organization_member' ;; # intentional typo caught below
          *)     die "Invalid --affiliation '${val}' (owner|all)" ;;
        esac
        shift ;;

      *) die "Unknown option: ${1}" ;;
    esac
  done

  # Fix possible typo path for AFFILIATION
  if [[ "${AFFILIATION:-}" == "" && "${AFFILIINATION:-}" != "" ]]; then
    AFFILIATION="${AFFILIINATION}"
  fi

  [[ -n "${DEST_DIR}" ]] || die "--dest-dir is required"
  [[ "${PARALLEL_JOBS}" -ge 1 ]] || die "--parallel must be >= 1"
}

# ---------- Core ----------
fetch_all_repos() {
  info "Fetching repo list (visibility='${VISIBILITY}', affiliation='${AFFILIATION}')..."
  local api_path='/user/repos'
  local params=(
    -H "Accept: application/vnd.github+json"
    -H "X-GitHub-Api-Version: 2022-11-28"
    "${api_path}?per_page=100&visibility=${VISIBILITY}&affiliation=${AFFILIATION}"
  )
  if ! gh api --paginate "${params[@]}" 2> "${TMP_DIR}/gh.stderr" | jq -s 'flatten' > "${REPOS_JSON}"; then
    error "Failed to fetch repositories. stderr:"
    cat "${TMP_DIR}/gh.stderr" >&2 || true
    exit 1
  fi
  local count; count="$(jq 'length' < "${REPOS_JSON}")"
  info "Retrieved ${count} repositories total (before filters)."
}

filter_repos() {
  local jq_filter='map(select(
    ('"${INCLUDE_FORKS}"' == "true" or (.fork | not))
    and
    ('"${INCLUDE_ARCHIVED}"' == "true" or (.archived | not))
  ))'
  debug "Filters: include_forks=${INCLUDE_FORKS}, include_archived=${INCLUDE_ARCHIVED}"
  jq "${jq_filter}" < "${REPOS_JSON}" > "${REPOS_JSON}.f" || die "jq failed to filter repos"
  mv "${REPOS_JSON}.f" "${REPOS_JSON}"
  local count; count="$(jq 'length' < "${REPOS_JSON}")"
  info "Remaining after filters: ${count} repositories."
}

list_targets() {
  # Output NUL-delimited "<name>\0<ssh_url>\0"
  jq -r -j '.[] | .name, "\u0000", .ssh_url, "\u0000"' < "${REPOS_JSON}"
}

record_failure() {
  local name="${1}"; shift
  local reason="${*:-unknown failure}"
  printf '%s: %s\n' "${name}" "${reason}" | tee -a "${FAIL_FILE}" "${LOG_FILE}" >&2
}

relax_submodules_to_default_branches() {
  # Try to put each submodule on its origin HEAD branch and update
  # Run inside repo dir
  git submodule foreach --recursive '
    set -e
    # if submodule dir is missing (init failed), skip
    if ! git rev-parse --is-inside-work-tree >/dev/null 2>&1; then
      exit 0
    fi
    git fetch --all >/dev/null 2>&1 || true
    default=$(git remote show origin 2>/dev/null | sed -n "s/.*HEAD branch: //p")
    if [ -n "$default" ]; then
      git checkout -q "$default" 2>/dev/null || true
      git pull --ff-only >/dev/null 2>&1 || true
    fi
    exit 0
  ' || true
}

clone_repo() {
  local seq="${1}" total="${2}" name="${3}" ssh_url="${4}"
  local repo_dir="${DEST_DIR}/${name}"
  local errf="${TMP_DIR}/${name}.stderr"
  : > "${errf}"

  info "(${seq}/${total}) ${name}"
  if [[ -d "${repo_dir}/.git" ]]; then
    info "Skip (exists): ${repo_dir}"
    return 0
  fi

  info "Cloning: ${name} -> ${repo_dir}"
  if [[ "${DRY_RUN}" == 'true' ]]; then
    echo "DRY-RUN: git clone --recurse-submodules ${ssh_url} '${repo_dir}'" | tee -a "${LOG_FILE}" >&2
    return 0
  fi

  if ! git clone --recurse-submodules "${ssh_url}" "${repo_dir}" 2>> "${errf}" | tee -a "${LOG_FILE}"; then
    record_failure "${name}" "git clone failed: $(tail -n 3 "${errf}" | tr '\n' ' ' | sed 's/  */ /g')"
    return 0
  fi

  (
    cd "${repo_dir}"

    # First attempt
    if git submodule update --init --recursive 2>> "${errf}" | tee -a "${LOG_FILE}"; then
      exit 0
    fi

    warn "Submodule init failed for ${name}. Retrying: sync -> update --jobs 1"
    git submodule sync --recursive 2>> "${errf}" || true
    if git submodule update --init --recursive --jobs 1 2>> "${errf}" | tee -a "${LOG_FILE}"; then
      exit 0
    fi

    warn "Submodule still failing for ${name}. Relaxing to default branches and retrying."
    relax_submodules_to_default_branches
    if git submodule update --init --recursive --jobs 1 2>> "${errf}" | tee -a "${LOG_FILE}"; then
      exit 0
    fi

    # Final failure
    record_failure "${name}" "submodule update failed after relax: $(tail -n 8 "${errf}" | tr '\n' ' ' | sed 's/  */ /g')"
    exit 0
  )
}

print_failure_summary() {
  if [[ ! -s "${FAIL_FILE}" ]]; then
    info "All repositories processed successfully."
    return 0
  fi
  echo "" >&2
  warn "Issues encountered:"
  sort -u "${FAIL_FILE}" | tee -a "${LOG_FILE}.failures" >&2
  warn "Saved list to: ${LOG_FILE}.failures"
  if [[ "${STRICT_EXIT}" == 'true' ]]; then
    exit 2
  fi
}

run_sequential() {
  local total="${1}"
  local seq=0
  while IFS= read -r -d '' name && IFS= read -r -d '' ssh_url; do
    seq=$((seq + 1))
    clone_repo "${seq}" "${total}" "${name}" "${ssh_url}"
  done < <(list_targets)
}

run_parallel() {
  local total="${1}"
  local running=0
  local seq=0

  while IFS= read -r -d '' name && IFS= read -r -d '' ssh_url; do
    seq=$((seq + 1))
    (
      # child process
      clone_repo "${seq}" "${total}" "${name}" "${ssh_url}"
    ) &
    running=$((running + 1))

    if (( running >= PARALLEL_JOBS )); then
      # Wait for any one job to finish before launching the next
      if ! wait -n; then :; fi
      running=$((running - 1))
    fi
  done < <(list_targets)

  # wait for the rest
  while (( running > 0 )); do
    if ! wait -n; then :; fi
    running=$((running - 1))
  done
}

main() {
  parse_args "$@"

  require_cmd gh
  require_cmd jq
  require_cmd git

  mkdir -p "${DEST_DIR}"
  : > "${FAIL_FILE}"

  info "Log file: ${LOG_FILE}"
  debug "DEST_DIR='${DEST_DIR}', VISIBILITY='${VISIBILITY}', AFFILIATION='${AFFILIATION}', INCLUDE_FORKS='${INCLUDE_FORKS}', INCLUDE_ARCHIVED='${INCLUDE_ARCHIVED}', DRY_RUN='${DRY_RUN}', STRICT_EXIT='${STRICT_EXIT}', PARALLEL_JOBS='${PARALLEL_JOBS}'"

  fetch_all_repos
  filter_repos

  local total; total="$(jq 'length' < "${REPOS_JSON}")"
  if [[ "${total}" -eq 0 ]]; then
    info "Nothing to do."
    return 0
  fi
  info "Will process ${total} repositories (parallel=${PARALLEL_JOBS})."

  if (( PARALLEL_JOBS > 1 )); then
    run_parallel "${total}"
  else
    run_sequential "${total}"
  fi

  print_failure_summary
}

if [[ "${BASH_SOURCE[0]}" == "$0" ]]; then
  main "$@"
fi
